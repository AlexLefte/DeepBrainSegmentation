[INFO: dataset.py:  134]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  134]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  134]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  134]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  134]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  134]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  134]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  134]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  134]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  143]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  143]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  150]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  150]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  150]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  153]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  153]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  153]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  152]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  165]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  165]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  173]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  173]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  173]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  175]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  167]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  150]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  150]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  143]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: val dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: val dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  278]: val dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  140]: train dataset loaded in  0.000 s.
Dataset length: 4.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  297]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  297]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  297]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  297]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  297]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  297]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  297]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  297]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  297]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  297]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  297]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  302]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  302]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  141]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  292]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  295]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  295]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[WARNING: legend.py: 1363]: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[INFO: main.py:   44]: ====Configuration:===
[INFO: main.py:   46]: exp_name: experiment_name
[INFO: main.py:   46]: exp_path: ./experiments
[INFO: main.py:   46]: about_experiment: Details about the performed experiment
[INFO: main.py:   46]: data_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\dataset
[INFO: main.py:   46]: train_size: 0.7
[INFO: main.py:   46]: valid_size: 0.15
[INFO: main.py:   46]: test_size: 0.15
[INFO: main.py:   46]: plane: coronal
[INFO: main.py:   46]: preprocessing_modality: percentiles_&_zscore
[INFO: main.py:   46]: data_padding: 320, 320, 320
[INFO: main.py:   46]: lr: 0.0005
[INFO: main.py:   46]: lr_sch_step: 10
[INFO: main.py:   46]: lr_sch_gamma: 0.5
[INFO: main.py:   46]: weight_decay: 1e-05
[INFO: main.py:   46]: batch_size: 16
[INFO: main.py:   46]: normalize_input: True
[INFO: main.py:   46]: loss_function: dice_loss_&_cross_entropy
[INFO: main.py:   46]: epochs: 10
[INFO: main.py:   46]: train_epochs: 10
[INFO: main.py:   46]: eval_net_epoch: 1
[INFO: main.py:   46]: save_net_epochs: 30
[INFO: main.py:   46]: lut_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\config\FastSurfer_ColorLUT.tsv
[INFO: main.py:   46]: in_channels: 1
[INFO: main.py:   46]: filters: 64
[INFO: main.py:   46]: kernel_h: 5
[INFO: main.py:   46]: kernel_w: 5
[INFO: main.py:   46]: stride: 1
[INFO: main.py:   46]: pool: 2
[INFO: main.py:   46]: pool_kernel: 1
[INFO: main.py:   46]: pool_stride: 2
[INFO: main.py:   46]: classifier_kernel: 1
[INFO: main.py:   46]: num_classes: 79
[INFO: main.py:   46]: device: cpu
[INFO: main.py:   46]: print_stats: 10
[INFO: main.py:   46]: resume_training: False
[INFO: main.py:   47]: =====================

[INFO: main.py:   44]: ====Configuration:===
[INFO: main.py:   46]: exp_name: experiment_name
[INFO: main.py:   46]: exp_path: ./experiments
[INFO: main.py:   46]: about_experiment: Details about the performed experiment
[INFO: main.py:   46]: data_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\dataset
[INFO: main.py:   46]: train_size: 0.7
[INFO: main.py:   46]: valid_size: 0.15
[INFO: main.py:   46]: test_size: 0.15
[INFO: main.py:   46]: plane: coronal
[INFO: main.py:   46]: preprocessing_modality: percentiles_&_zscore
[INFO: main.py:   46]: data_padding: 320, 320, 320
[INFO: main.py:   46]: lr: 0.0005
[INFO: main.py:   46]: lr_sch_step: 10
[INFO: main.py:   46]: lr_sch_gamma: 0.5
[INFO: main.py:   46]: weight_decay: 1e-05
[INFO: main.py:   46]: batch_size: 16
[INFO: main.py:   46]: normalize_input: True
[INFO: main.py:   46]: loss_function: dice_loss_&_cross_entropy
[INFO: main.py:   46]: epochs: 10
[INFO: main.py:   46]: train_epochs: 10
[INFO: main.py:   46]: eval_net_epoch: 1
[INFO: main.py:   46]: save_net_epochs: 30
[INFO: main.py:   46]: lut_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\config\FastSurfer_ColorLUT.tsv
[INFO: main.py:   46]: in_channels: 1
[INFO: main.py:   46]: filters: 64
[INFO: main.py:   46]: kernel_h: 5
[INFO: main.py:   46]: kernel_w: 5
[INFO: main.py:   46]: stride: 1
[INFO: main.py:   46]: pool: 2
[INFO: main.py:   46]: pool_kernel: 1
[INFO: main.py:   46]: pool_stride: 2
[INFO: main.py:   46]: classifier_kernel: 1
[INFO: main.py:   46]: num_classes: 79
[INFO: main.py:   46]: device: cpu
[INFO: main.py:   46]: print_stats: 10
[INFO: main.py:   46]: resume_training: False
[INFO: main.py:   47]: =====================

[INFO: main.py:   55]: Device: cpu
[INFO: main.py:   63]: Number of parameters: 2674346
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: trainer.py:  241]: ====Started training...====
[INFO: trainer.py:   70]: Training started
[INFO: main.py:   44]: ====Configuration:===
[INFO: main.py:   46]: exp_name: experiment_name
[INFO: main.py:   46]: exp_path: ./experiments
[INFO: main.py:   46]: about_experiment: Details about the performed experiment
[INFO: main.py:   46]: data_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\dataset
[INFO: main.py:   46]: train_size: 0.7
[INFO: main.py:   46]: valid_size: 0.15
[INFO: main.py:   46]: test_size: 0.15
[INFO: main.py:   46]: plane: coronal
[INFO: main.py:   46]: preprocessing_modality: percentiles_&_zscore
[INFO: main.py:   46]: data_padding: 320, 320, 320
[INFO: main.py:   46]: lr: 0.0005
[INFO: main.py:   46]: lr_sch_step: 10
[INFO: main.py:   46]: lr_sch_gamma: 0.5
[INFO: main.py:   46]: weight_decay: 1e-05
[INFO: main.py:   46]: batch_size: 16
[INFO: main.py:   46]: normalize_input: True
[INFO: main.py:   46]: loss_function: dice_loss_&_cross_entropy
[INFO: main.py:   46]: epochs: 10
[INFO: main.py:   46]: train_epochs: 10
[INFO: main.py:   46]: eval_net_epoch: 1
[INFO: main.py:   46]: save_net_epochs: 30
[INFO: main.py:   46]: lut_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\config\FastSurfer_ColorLUT.tsv
[INFO: main.py:   46]: in_channels: 1
[INFO: main.py:   46]: filters: 64
[INFO: main.py:   46]: kernel_h: 5
[INFO: main.py:   46]: kernel_w: 5
[INFO: main.py:   46]: stride: 1
[INFO: main.py:   46]: pool: 2
[INFO: main.py:   46]: pool_kernel: 1
[INFO: main.py:   46]: pool_stride: 2
[INFO: main.py:   46]: classifier_kernel: 1
[INFO: main.py:   46]: num_classes: 79
[INFO: main.py:   46]: device: cpu
[INFO: main.py:   46]: print_stats: 10
[INFO: main.py:   46]: resume_training: False
[INFO: main.py:   47]: =====================

[INFO: main.py:   55]: Device: cpu
[INFO: main.py:   63]: Number of parameters: 2674346
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: trainer.py:  241]: ====Started training...====
[INFO: trainer.py:   70]: Training started
[INFO: main.py:   44]: ====Configuration:===
[INFO: main.py:   46]: exp_name: experiment_name
[INFO: main.py:   46]: exp_path: ./experiments
[INFO: main.py:   46]: about_experiment: Details about the performed experiment
[INFO: main.py:   46]: data_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\dataset
[INFO: main.py:   46]: train_size: 0.7
[INFO: main.py:   46]: valid_size: 0.15
[INFO: main.py:   46]: test_size: 0.15
[INFO: main.py:   46]: plane: coronal
[INFO: main.py:   46]: preprocessing_modality: percentiles_&_zscore
[INFO: main.py:   46]: data_padding: 320, 320, 320
[INFO: main.py:   46]: lr: 0.0005
[INFO: main.py:   46]: lr_sch_step: 10
[INFO: main.py:   46]: lr_sch_gamma: 0.5
[INFO: main.py:   46]: weight_decay: 1e-05
[INFO: main.py:   46]: batch_size: 16
[INFO: main.py:   46]: normalize_input: True
[INFO: main.py:   46]: loss_function: dice_loss_&_cross_entropy
[INFO: main.py:   46]: epochs: 10
[INFO: main.py:   46]: train_epochs: 10
[INFO: main.py:   46]: eval_net_epoch: 1
[INFO: main.py:   46]: save_net_epochs: 30
[INFO: main.py:   46]: lut_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\config\FastSurfer_ColorLUT.tsv
[INFO: main.py:   46]: in_channels: 1
[INFO: main.py:   46]: filters: 64
[INFO: main.py:   46]: kernel_h: 5
[INFO: main.py:   46]: kernel_w: 5
[INFO: main.py:   46]: stride: 1
[INFO: main.py:   46]: pool: 2
[INFO: main.py:   46]: pool_kernel: 1
[INFO: main.py:   46]: pool_stride: 2
[INFO: main.py:   46]: classifier_kernel: 1
[INFO: main.py:   46]: num_classes: 79
[INFO: main.py:   46]: device: cpu
[INFO: main.py:   46]: print_stats: 10
[INFO: main.py:   46]: resume_training: False
[INFO: main.py:   47]: =====================

[INFO: main.py:   55]: Device: cpu
[INFO: main.py:   63]: Number of parameters: 2674346
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: trainer.py:  241]: ====Started training...====
[INFO: trainer.py:   70]: Training started
[INFO: main.py:   44]: ====Configuration:===
[INFO: main.py:   46]: exp_name: experiment_name
[INFO: main.py:   46]: exp_path: ./experiments
[INFO: main.py:   46]: about_experiment: Details about the performed experiment
[INFO: main.py:   46]: data_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\dataset
[INFO: main.py:   46]: train_size: 0.7
[INFO: main.py:   46]: valid_size: 0.15
[INFO: main.py:   46]: test_size: 0.15
[INFO: main.py:   46]: plane: coronal
[INFO: main.py:   46]: preprocessing_modality: percentiles_&_zscore
[INFO: main.py:   46]: data_padding: 320, 320, 320
[INFO: main.py:   46]: lr: 0.0005
[INFO: main.py:   46]: lr_sch_step: 10
[INFO: main.py:   46]: lr_sch_gamma: 0.5
[INFO: main.py:   46]: weight_decay: 1e-05
[INFO: main.py:   46]: batch_size: 16
[INFO: main.py:   46]: normalize_input: True
[INFO: main.py:   46]: loss_function: dice_loss_&_cross_entropy
[INFO: main.py:   46]: epochs: 10
[INFO: main.py:   46]: train_epochs: 10
[INFO: main.py:   46]: eval_net_epoch: 1
[INFO: main.py:   46]: save_net_epochs: 30
[INFO: main.py:   46]: lut_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\config\FastSurfer_ColorLUT.tsv
[INFO: main.py:   46]: in_channels: 1
[INFO: main.py:   46]: filters: 64
[INFO: main.py:   46]: kernel_h: 5
[INFO: main.py:   46]: kernel_w: 5
[INFO: main.py:   46]: stride: 1
[INFO: main.py:   46]: pool: 2
[INFO: main.py:   46]: pool_kernel: 1
[INFO: main.py:   46]: pool_stride: 2
[INFO: main.py:   46]: classifier_kernel: 1
[INFO: main.py:   46]: num_classes: 79
[INFO: main.py:   46]: device: cpu
[INFO: main.py:   46]: print_stats: 10
[INFO: main.py:   46]: resume_training: False
[INFO: main.py:   47]: =====================

[INFO: main.py:   55]: Device: cpu
[INFO: main.py:   63]: Number of parameters: 2674346
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: trainer.py:  241]: ====Started training...====
[INFO: trainer.py:   70]: Training started
[INFO: main.py:   44]: ====Configuration:===
[INFO: main.py:   46]: exp_name: experiment_name
[INFO: main.py:   46]: exp_path: ./experiments
[INFO: main.py:   46]: about_experiment: Details about the performed experiment
[INFO: main.py:   46]: data_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\dataset
[INFO: main.py:   46]: train_size: 0.7
[INFO: main.py:   46]: valid_size: 0.15
[INFO: main.py:   46]: test_size: 0.15
[INFO: main.py:   46]: plane: coronal
[INFO: main.py:   46]: preprocessing_modality: percentiles_&_zscore
[INFO: main.py:   46]: data_padding: 320, 320, 320
[INFO: main.py:   46]: lr: 0.0005
[INFO: main.py:   46]: lr_sch_step: 10
[INFO: main.py:   46]: lr_sch_gamma: 0.5
[INFO: main.py:   46]: weight_decay: 1e-05
[INFO: main.py:   46]: batch_size: 16
[INFO: main.py:   46]: normalize_input: True
[INFO: main.py:   46]: loss_function: dice_loss_&_cross_entropy
[INFO: main.py:   46]: epochs: 10
[INFO: main.py:   46]: train_epochs: 10
[INFO: main.py:   46]: eval_net_epoch: 1
[INFO: main.py:   46]: save_net_epochs: 30
[INFO: main.py:   46]: lut_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\config\FastSurfer_ColorLUT.tsv
[INFO: main.py:   46]: in_channels: 1
[INFO: main.py:   46]: filters: 64
[INFO: main.py:   46]: kernel_h: 5
[INFO: main.py:   46]: kernel_w: 5
[INFO: main.py:   46]: stride: 1
[INFO: main.py:   46]: pool: 2
[INFO: main.py:   46]: pool_kernel: 1
[INFO: main.py:   46]: pool_stride: 2
[INFO: main.py:   46]: classifier_kernel: 1
[INFO: main.py:   46]: num_classes: 79
[INFO: main.py:   46]: device: cpu
[INFO: main.py:   46]: print_stats: 10
[INFO: main.py:   46]: resume_training: False
[INFO: main.py:   46]: summary_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\src\experiments\summary
[INFO: main.py:   47]: =====================

[INFO: main.py:   55]: Device: cpu
[INFO: main.py:   63]: Number of parameters: 2674346
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: trainer.py:  241]: ====Started training...====
[INFO: trainer.py:   70]: Training started
[INFO: trainer.py:  143]: Training step is finished in: 440.153591632843 seconds.
[INFO: trainer.py:   70]: Training started
[INFO: main.py:   44]: ====Configuration:===
[INFO: main.py:   46]: exp_name: experiment_name
[INFO: main.py:   46]: exp_path: ./experiments
[INFO: main.py:   46]: about_experiment: Details about the performed experiment
[INFO: main.py:   46]: data_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\dataset
[INFO: main.py:   46]: train_size: 0.7
[INFO: main.py:   46]: valid_size: 0.15
[INFO: main.py:   46]: test_size: 0.15
[INFO: main.py:   46]: plane: coronal
[INFO: main.py:   46]: preprocessing_modality: percentiles_&_zscore
[INFO: main.py:   46]: data_padding: 320, 320, 320
[INFO: main.py:   46]: lr: 0.0005
[INFO: main.py:   46]: lr_sch_step: 10
[INFO: main.py:   46]: lr_sch_gamma: 0.5
[INFO: main.py:   46]: weight_decay: 1e-05
[INFO: main.py:   46]: batch_size: 16
[INFO: main.py:   46]: normalize_input: True
[INFO: main.py:   46]: loss_function: dice_loss_&_cross_entropy
[INFO: main.py:   46]: epochs: 10
[INFO: main.py:   46]: train_epochs: 10
[INFO: main.py:   46]: eval_net_epoch: 1
[INFO: main.py:   46]: save_net_epochs: 30
[INFO: main.py:   46]: lut_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\config\FastSurfer_ColorLUT.tsv
[INFO: main.py:   46]: in_channels: 1
[INFO: main.py:   46]: filters: 64
[INFO: main.py:   46]: kernel_h: 5
[INFO: main.py:   46]: kernel_w: 5
[INFO: main.py:   46]: stride: 1
[INFO: main.py:   46]: pool: 2
[INFO: main.py:   46]: pool_kernel: 1
[INFO: main.py:   46]: pool_stride: 2
[INFO: main.py:   46]: classifier_kernel: 1
[INFO: main.py:   46]: num_classes: 79
[INFO: main.py:   46]: device: cpu
[INFO: main.py:   46]: print_stats: 10
[INFO: main.py:   46]: resume_training: False
[INFO: main.py:   46]: summary_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\src\experiments\summary
[INFO: main.py:   47]: =====================

[INFO: main.py:   55]: Device: cpu
[INFO: main.py:   63]: Number of parameters: 2674346
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: trainer.py:  240]: ====Started training...====
[INFO: trainer.py:   70]: Training started
[INFO: main.py:   44]: ====Configuration:===
[INFO: main.py:   46]: exp_name: experiment_name
[INFO: main.py:   46]: exp_path: ./experiments
[INFO: main.py:   46]: about_experiment: Details about the performed experiment
[INFO: main.py:   46]: data_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\dataset
[INFO: main.py:   46]: train_size: 0.7
[INFO: main.py:   46]: valid_size: 0.15
[INFO: main.py:   46]: test_size: 0.15
[INFO: main.py:   46]: plane: coronal
[INFO: main.py:   46]: preprocessing_modality: percentiles_&_zscore
[INFO: main.py:   46]: data_padding: 320, 320, 320
[INFO: main.py:   46]: lr: 0.0005
[INFO: main.py:   46]: lr_sch_step: 10
[INFO: main.py:   46]: lr_sch_gamma: 0.5
[INFO: main.py:   46]: weight_decay: 1e-05
[INFO: main.py:   46]: batch_size: 16
[INFO: main.py:   46]: normalize_input: True
[INFO: main.py:   46]: loss_function: dice_loss_&_cross_entropy
[INFO: main.py:   46]: epochs: 10
[INFO: main.py:   46]: train_epochs: 10
[INFO: main.py:   46]: eval_net_epoch: 1
[INFO: main.py:   46]: save_net_epochs: 30
[INFO: main.py:   46]: lut_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\config\FastSurfer_ColorLUT.tsv
[INFO: main.py:   46]: in_channels: 1
[INFO: main.py:   46]: filters: 64
[INFO: main.py:   46]: kernel_h: 5
[INFO: main.py:   46]: kernel_w: 5
[INFO: main.py:   46]: stride: 1
[INFO: main.py:   46]: pool: 2
[INFO: main.py:   46]: pool_kernel: 1
[INFO: main.py:   46]: pool_stride: 2
[INFO: main.py:   46]: classifier_kernel: 1
[INFO: main.py:   46]: num_classes: 79
[INFO: main.py:   46]: device: cpu
[INFO: main.py:   46]: print_stats: 10
[INFO: main.py:   46]: resume_training: False
[INFO: main.py:   46]: summary_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\src\experiments\summary
[INFO: main.py:   47]: =====================

[INFO: main.py:   55]: Device: cpu
[INFO: main.py:   63]: Number of parameters: 2674346
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: trainer.py:  240]: ====Started training...====
[INFO: trainer.py:   70]: Training started
[INFO: trainer.py:  142]: Training step is finished in: 476.6508638858795 seconds.
[INFO: trainer.py:   70]: Training started
[INFO: main.py:   44]: ====Configuration:===
[INFO: main.py:   46]: exp_name: experiment_name
[INFO: main.py:   46]: exp_path: ./experiments
[INFO: main.py:   46]: about_experiment: Details about the performed experiment
[INFO: main.py:   46]: data_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\dataset
[INFO: main.py:   46]: train_size: 0.7
[INFO: main.py:   46]: valid_size: 0.15
[INFO: main.py:   46]: test_size: 0.15
[INFO: main.py:   46]: plane: coronal
[INFO: main.py:   46]: preprocessing_modality: percentiles_&_zscore
[INFO: main.py:   46]: data_padding: 320, 320, 320
[INFO: main.py:   46]: lr: 0.0005
[INFO: main.py:   46]: lr_sch_step: 10
[INFO: main.py:   46]: lr_sch_gamma: 0.5
[INFO: main.py:   46]: weight_decay: 1e-05
[INFO: main.py:   46]: batch_size: 16
[INFO: main.py:   46]: normalize_input: True
[INFO: main.py:   46]: loss_function: dice_loss_&_cross_entropy
[INFO: main.py:   46]: epochs: 10
[INFO: main.py:   46]: train_epochs: 10
[INFO: main.py:   46]: eval_net_epoch: 1
[INFO: main.py:   46]: save_net_epochs: 30
[INFO: main.py:   46]: lut_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\config\FastSurfer_ColorLUT.tsv
[INFO: main.py:   46]: in_channels: 1
[INFO: main.py:   46]: filters: 64
[INFO: main.py:   46]: kernel_h: 5
[INFO: main.py:   46]: kernel_w: 5
[INFO: main.py:   46]: stride: 1
[INFO: main.py:   46]: pool: 2
[INFO: main.py:   46]: pool_kernel: 1
[INFO: main.py:   46]: pool_stride: 2
[INFO: main.py:   46]: classifier_kernel: 1
[INFO: main.py:   46]: num_classes: 79
[INFO: main.py:   46]: device: cpu
[INFO: main.py:   46]: print_stats: 10
[INFO: main.py:   46]: resume_training: False
[INFO: main.py:   46]: summary_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\src\experiments\summary
[INFO: main.py:   47]: =====================

[INFO: main.py:   55]: Device: cpu
[INFO: main.py:   63]: Number of parameters: 2674346
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: dataset.py:  298]: eval dataset loaded in  0.000 s.
Dataset length: 180.
[INFO: trainer.py:  240]: ====Started training...====
[INFO: trainer.py:   70]: Training started
[INFO: main.py:   44]: ====Configuration:===
[INFO: main.py:   46]: exp_name: experiment_name
[INFO: main.py:   46]: exp_path: ./experiments
[INFO: main.py:   46]: about_experiment: Details about the performed experiment
[INFO: main.py:   46]: data_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\dataset
[INFO: main.py:   46]: train_size: 0.7
[INFO: main.py:   46]: valid_size: 0.15
[INFO: main.py:   46]: test_size: 0.15
[INFO: main.py:   46]: plane: coronal
[INFO: main.py:   46]: preprocessing_modality: percentiles_&_zscore
[INFO: main.py:   46]: data_padding: 320, 320, 320
[INFO: main.py:   46]: lr: 0.0005
[INFO: main.py:   46]: lr_sch_step: 10
[INFO: main.py:   46]: lr_sch_gamma: 0.5
[INFO: main.py:   46]: weight_decay: 1e-05
[INFO: main.py:   46]: batch_size: 16
[INFO: main.py:   46]: normalize_input: True
[INFO: main.py:   46]: loss_function: dice_loss_&_cross_entropy
[INFO: main.py:   46]: epochs: 10
[INFO: main.py:   46]: train_epochs: 10
[INFO: main.py:   46]: eval_net_epoch: 1
[INFO: main.py:   46]: save_net_epochs: 30
[INFO: main.py:   46]: lut_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\config\FastSurfer_ColorLUT.tsv
[INFO: main.py:   46]: in_channels: 1
[INFO: main.py:   46]: filters: 64
[INFO: main.py:   46]: kernel_h: 5
[INFO: main.py:   46]: kernel_w: 5
[INFO: main.py:   46]: stride: 1
[INFO: main.py:   46]: pool: 2
[INFO: main.py:   46]: pool_kernel: 1
[INFO: main.py:   46]: pool_stride: 2
[INFO: main.py:   46]: classifier_kernel: 1
[INFO: main.py:   46]: num_classes: 79
[INFO: main.py:   46]: device: cpu
[INFO: main.py:   46]: print_stats: 10
[INFO: main.py:   46]: resume_training: False
[INFO: main.py:   46]: summary_path: C:\Users\Engineer\Documents\Updates\Repo\DeepBrainSegmentation\src\experiments\summary
[INFO: main.py:   47]: =====================

[INFO: main.py:   55]: Device: cpu
[INFO: main.py:   63]: Number of parameters: 2674346
[INFO: dataset.py:  142]: train dataset loaded in  0.000 s.
Dataset length: 180.
